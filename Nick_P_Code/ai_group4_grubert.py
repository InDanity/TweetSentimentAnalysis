# -*- coding: utf-8 -*-
"""ai_group4_grubert.ipynb

Automatically generated by Colab.
Code by Group 4

Original file is located at
    https://colab.research.google.com/drive/1DD1Ct8yEpm1XjC2QeK2FxJAIUwBa2y8z

# Setup: Install Packages
"""

from google.colab import files
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_auc_score
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt
import pandas as pd

# NOTE this code was developed and tested on a google colab jupyter notebook
# (so there may be some quirks running it as a raw .py)
# NOTE the training data is automatically downloaded from the code, but a kaggle
# account certificate is required

ELECTION_FPATH = '/content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/trump_harris_tweets.csv'

# download python3.7.4 and switch configuration to it
!sudo apt-get update -y
!sudo apt-get install python3.7
!sudo apt install python3-pip
!sudo apt install python3.7-distutils
!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1
!sudo apt-get install python3-jsonnet
!python -V

# Commented out IPython magic to ensure Python compatibility.
# install GRUBERT model and requirements
!git clone https://github.com/ZuowenWang0000/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis.git
# %cd GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis
!pip3 install allennlp==0.9.0
!pip3 install torch==1.5.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html
!pip3 install --user -r requirements.txt
!pip3 install tensorboard
#%cd ..

"""# Download/Preprocess the Data"""

# initalize dataset/kaggle environement
!pip3 install -q kaggle
files.upload()
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c tweet-sentiment-extraction
!unzip tweet-sentiment-extraction.zip

traindf = pd.read_csv('train.csv')
testdf = pd.read_csv('test.csv')
electiondf = pd.read_csv(ELECTION_FPATH)

# convert labels
traindf = traindf[['text', 'sentiment']]
testdf = testdf[['text', 'sentiment']]
sentiment_mapping = {
    'positive': 2,
    'neutral': 1,
    'negative': 0
}
traindf['sentiment'] = traindf['sentiment'].map(sentiment_mapping)
testdf['sentiment'] = testdf['sentiment'].map(sentiment_mapping)
trainidx = [x for x in range(traindf.shape[0])]
testidx = [x for x in range(testdf.shape[0])]
traindf['index'] = trainidx
testdf['index'] = testidx
traindf.rename(columns={"index":"index","text": "text", "sentiment": "label"}, inplace=True)
testdf.rename(columns={"index":"index","text": "text", "sentiment": "label"}, inplace=True)
print(traindf.head())

# split the data into training and validation
ratio = 0.9

total_rows = traindf.shape[0]
train_size = int(total_rows*ratio)
print(f'Training size: {train_size}, total rows: {total_rows}')

# Split data into test and train
valdf = traindf[train_size:]
traindf = traindf[0:train_size]

# save the dfs back as csvs
traindf.to_csv('train.csv', index=False)
valdf.to_csv('val.csv', index=False)
testdf.to_csv('test.csv', index=False)

# show the election data
print("Election tweets:")
electiondf.head()

# designate first 20 rows of testing as election tweets (for convienience)
for i in range(10):
  testdf.loc[i, 'text'] = electiondf.loc[i, 'trump']

for i in range(10, 20):
  testdf.loc[i, 'text'] = electiondf.loc[i-10, 'harris']

testdf.to_csv('test.csv', index=False)

"""# Train the model"""

# invoke GRUBERT code to run training
!python train.py --config /content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/bert_share_3_tse_tune.json --embedding bert-mix --seed 0
#!python train.py --help --seed 0

"""# Make predictions"""

# invoke GRUBERT code to run preditions
!python predict.py --config /content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/bert_share_3_tse_tune.json --embedding bert-mix --checkpoint /content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/checkpoint_epoch_3.pth.tar --predict-file ./pred_cat_2.csv

# compare output file with test.tsv and calculate metrics
prediction_fname = '/content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/pred_cat_2.csv'

preddf = pd.read_csv(prediction_fname)
y_true = testdf['label']
y_pred = preddf['Prediction']
y_true.head()
y_pred.head()

# Calculate metrics
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')

#auc = roc_auc_score(y_true, preddf['pred_proba'])

# Print metrics
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
#print(f'AUC: {auc}')

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1, 2])
disp.plot(cmap=plt.cm.Blues)  # You can choose any colormap
plt.title('GRUBERT Confusion Matrix')
plt.show()

# per class matrix summary
report = classification_report(y_true, y_pred, output_dict=True)
accuracy_per_class = {key: value['f1-score'] for key, value in report.items() if key.isdigit()}
print(report)

accuracy_per_class = accuracy_score(y_true, y_pred, normalize=False)
precision_per_class = precision_score(y_true, y_pred, average=None)
recall_per_class = recall_score(y_true, y_pred, average=None)
f1_per_class = f1_score(y_true, y_pred, average=None)

# Create a DataFrame to summarize the metrics
metrics_summary = pd.DataFrame({
    'Class': [0, 1, 2],
    'Precision': precision_per_class,
    'Recall': recall_per_class,
    'F1 Score': f1_per_class
})

# Calculate ROC-AUC
y_true_binarized = label_binarize(y_true, classes=[0, 1, 2])
probsdf = pd.read_csv('/content/GRUBERT-A-GRU-Based-Method-to-Fuse-BERT-Hidden-Layers-for-Twitter-sentiment-analysis/pred_cat_prob.csv')
auc_scores = {}
for i in range(3):
    if i == 0:
        y_pred_proba = probsdf['Prob0']
    elif i == 1:
        y_pred_proba = probsdf['Prob1']
    else:
        y_pred_proba = probsdf['Prob2']
    auc_scores[i] = roc_auc_score(y_true_binarized[:, i], [x for x in y_pred_proba])

print(f"AUC-ROC Value: {auc_scores}")

print(metrics_summary)

# save results as csv
y_pred.to_csv('ypred.csv', index=False)
y_true.to_csv('ytrue.csv', index=False)
